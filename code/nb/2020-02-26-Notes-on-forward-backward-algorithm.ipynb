{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are some notes on the Forward-Backward algorithm for Hidden Markov Models (HMMs). The focus of this post is on the derivations and on the variations of these algorithms. When possible I try to give an interpretation of the probabilities involved. \n",
    "\n",
    "Some basic understanding of HMMs is probably needed before reading this text. Reference [[1]](#1) provides a in-depth introduction and good resources are available also online for example on Wikipedia's webpages on [HMMs](https://en.wikipedia.org/wiki/Hidden_Markov_model) and [forward-backward algorithms](https://en.wikipedia.org/wiki/Forward–backward_algorithm). \n",
    "\n",
    "Here some code snippets are shown. They are written in the Julia language and should be very readable, as simple as pseudo-code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov model notation\n",
    "\n",
    "The states of a Hidden Markov Model (HMM) $s_j \\in \\mathcal{N}$ for $j=1,\\dots,N_s$ are defined as integers.\n",
    "A state sequence is the vector $\\mathbf{s} \\in \\mathcal{N}^{N_t}$, where $N_t$ is the number of time steps.\n",
    "\n",
    "\n",
    "The parameters of the HMM are defined in $ \\lambda = \\{\\mathbf{A}, \\mathbf{a}, \\mathcal{B}  \\}$.\n",
    "\n",
    "\n",
    "Here $\\mathbf{A} \\in \\mathcal{R}^{N_s \\times N_s}$ transition matrix where $p(s_t=j|s_{t-1}=i)= a_{ij}$ with $a_{ij}$ being the $(i,j)$-th element of $\\mathbf{A}$ (Markov process of order 1) and \n",
    "$\\mathbf{a} \\in \\mathcal{R}^{N_s}$ are the initial state probability.\n",
    "$\\mathcal{B} = \\{ b_1, \\dots b_{N_s} \\}$ are a set of distributions, one per state where $p(y_t|s_j)=b_{j}(y_t)$ (observation independence, memoryless model) where $y_t$ is the observation at the time $t$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions, LinearAlgebra, Combinatorics\n",
    "\n",
    "# define Markov model's parameters (λ)\n",
    "Ns = 2          # number of states\n",
    "a = [0.5; 0.5]  # initial state probability  \n",
    "A = [0.7 0.3; 0.3 0.7] # transmission Matrix  [a_11 a21; a12 a_22]\n",
    "# Must be row stotastic: [sum(A[i,:]) for i in 1:size(A,1)] .== 1\n",
    "\n",
    "B = [Categorical([0.9, 0.1]), Categorical([0.2, 0.8])] \n",
    "# observation distribution [b_1; b_2]\n",
    "# Tells what is the probability of a state given an observation  P(y_t|s_i)\n",
    "# e.g. `pdf(D[1],2) == 0.1` gives the probability \n",
    "# of being in state 1 if we observed y_t = 2 \n",
    "return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior likelihood\n",
    "\n",
    "Say we have an observation $\\mathbf{y} \\in \\mathcal{R}^{N_t}$ where $N_t$ is an integer indicating time steps.\n",
    "\n",
    "Let's compute the likelihood between our Markov model with parameters $\\lambda$ and the observations $\\mathbf{y}$.\n",
    "\n",
    "Using the law of total probability, this likelihood can be defined as:\n",
    "\n",
    "$p_\\lambda ( \\mathbf{y} ) =  \n",
    "\\sum_{\\mathbf{s} \\in \\mathcal{S}} p_{\\lambda} (\\mathbf{y} | \\mathbf{s} ) p( \\mathbf{s} ) $\n",
    "\n",
    "where\n",
    "$ p_{\\lambda} (\\mathbf{y} | \\mathbf{s} ) $ is the likelihood of observation given a state sequence $\\mathbf{s} \\in \\mathcal{N}^{N_t}$,\n",
    "$ p( \\mathbf{s} ) $ is probability of a particular state sequence and\n",
    "$ \\mathcal{S} $ is a set containing all possible state sequences.  \n",
    "\n",
    "Obtaining $p_{\\lambda}(\\mathbf{y})$ is necessary in different circumstances, for example when learning the parameters $\\lambda$.\n",
    "\n",
    "In this case we want to maximize $p_{\\lambda}(\\mathbf{y})$:\n",
    "\n",
    "$\\lambda^\\star = \\arg \\max _{\\lambda} p_{\\lambda} (\\mathbf{y})$\n",
    "\n",
    "where $\\lambda^\\star$ is the set of parameters such that a local maximum is reached.\n",
    "\n",
    "This problem is generally a nonconcave (nonconvex) problem. Typically an _expectation–maximization (EM) procedure_ is used to solve this optimization problem.\n",
    "\n",
    "A simplified summary of EM algorithm is the following:\n",
    "  0. start from an initial guess of $\\lambda^0$ and iteration $k = 0$\n",
    "  1. find a concave approximation (auxiliary function) of $p_\\lambda(\\mathbf{y})$, call it $ Q(\\lambda, \\lambda^{k}) $\n",
    "  2. solve $\\lambda^{k+1} = \\arg \\max_{\\lambda} Q(\\lambda, \\lambda^{k})$ \n",
    "  3. check if stopping criteria is reached otherwise $k \\leftarrow k+1$ and go to 1\n",
    "\n",
    "More information about the EM algorithm can be found in [[2]](#2).\n",
    "  \n",
    "Solving the optimization problem of point $2$ can performed efficiently using the forward-backward algorithm.\n",
    "\n",
    "Let's first have a look at the simplest approach for computing $p_\\lambda(\\mathbf{y})$\n",
    "to start with a baseline.\n",
    "\n",
    "We can compute $p_\\lambda ( \\mathbf{y} )$ using brute force, \n",
    "i.e. for all of the elements of $\\mathcal{S}$. \n",
    "\n",
    "What we need is \n",
    "$p_\\lambda (\\mathbf{y} | \\mathbf{s} ) = \\prod_{t = 1}^{N_t} b_{s_t} (y_t)$ where $y_t$ is the $t$-th element of $\\mathbf{y}$ (observation independence) and\n",
    "$P_\\lambda (\\mathbf{s}) = a_{s_0} \\prod_{t = 1}^T a_{s_{t-1},s_t}$ where \n",
    "$a_{s_0}$ is the $s_0$-th element of $\\mathbf{a}$ and \n",
    "$a_{s_{t-1},s_t}$ is the $(s_{t-1},s_t)$-th of $\\mathbf{A}$  (Markov process order 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03430370049999999"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nt = 5                     # time window length\n",
    "y = [1;1;2;1;1]            # observations\n",
    "\n",
    "s_all = collect(multiset_permutations([1;2],[5;5],5))\n",
    "\n",
    "# this has all possible state sequences e.g. [1;1;1;1;1], [1;1;1;1;2] ...\n",
    "# these are Ns^Nt permutations\n",
    "\n",
    "# Probability of sequence of states\n",
    "Pλ_s = zeros(length(s_all)) \n",
    "for z = 1:length(s_all)\n",
    "    Pλ_s[z] = a[1] # initial distribution, since they are equal so we don't need to do this twice\n",
    "    for t = 2:Nt\n",
    "        Pλ_s[z] *= A[ s_all[z][t-1], s_all[z][t] ]\n",
    "    end\n",
    "end\n",
    "@assert sum(Pλ_s) ≈ 1 # check it's a probability \n",
    "\n",
    "# Likelihood of O given a sequence of states\n",
    "pλ_y_s = ones(length(s_all)) \n",
    "for z = 1:length(s_all)\n",
    "    for t = 1:Nt\n",
    "        pλ_y_s[z] *= pdf(B[ s_all[z][t] ], y[t])\n",
    "    end\n",
    "end\n",
    "\n",
    "Pλ = sum(Pλ_s .* pλ_y_s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baum's forward\n",
    "\n",
    "Brute force can easily become intractable since we have to compute likelihoods and probabilities for $N_s^{N_t}$ times.\n",
    "\n",
    "It is possible to express $p_\\lambda (\\mathbf{y})$ by marginalizing the likelihood at a specific time $t$:    \n",
    "\n",
    "$p_\\lambda (\\mathbf{y}) = \\sum_{j = 1}^{N_s} p_{\\lambda} (\\mathbf{y}, s_t = j),$\n",
    "\n",
    "using the conditional probability definition we can further decompose the summand into: \n",
    "\n",
    "$ p_{\\lambda} (\\mathbf{y},s_t = j) =  \n",
    "p_{\\lambda} (y_1, \\dots, y_t, s_t = j) \\cdot p_{\\lambda} (y_{t+1} \\dots y_{T} | y_1, \\dots, y_t, s_t = j) $\n",
    "\n",
    "and drop the dependence of $\\{ y_1, \\dots, y_t \\}$ in the conditional likelihood since it is independent of previous states (observation independence).\n",
    "\n",
    "We can now define the two terms of the product as:\n",
    "\n",
    "* $\\alpha_j(t) =  p_{\\lambda} (y_1, \\dots, y_t, s_t = j)$\n",
    "* $\\beta_j (t) = p_{\\lambda} (y_{t+1} \\dots y_{N_t} | s_t = j)$\n",
    "\n",
    "We need to manipulate $\\alpha_j(t)$ as follows: \n",
    "\n",
    "* $p_{\\lambda} (y_1, \\dots, y_t, s_t = j) = \\sum_{i=1}^{N_s} p_{\\lambda} (y_1, \\dots, y_t, s_t = j, s_{t-1} = i)$ \n",
    "marginalization\n",
    "\n",
    "* $\\sum_{i=1}^{N_s} p_{\\lambda} (y_1, \\dots, y_t, s_t = j, s_{t-1} = i) = \n",
    "\\sum_{i=1}^{N_s} p_{\\lambda} (y_1, \\dots, y_{t-1}, s_{t-1} = i) \\cdot p_{\\lambda}(y_t, s_t = j |  y_1, \\dots, y_{t-1}, s_{t-1} = i) $ conditional probability definition\n",
    "\n",
    "* $\n",
    "\\sum_{i=1}^{N_s} \\alpha_{t-1}(i) \\cdot p_{\\lambda}(y_{t}, s_t = j | y_{t-1}, s_{t-1} = i) \n",
    "= \\sum_{i=1}^{N_s} \\alpha_{t-1}(i) \n",
    "\\cdot p_{\\lambda}(y_{t} |  y_{t-1}, s_t = j, s_{t-1} = i) \n",
    "\\cdot p_{\\lambda}(s_t = j | y_t, y_{t-1}, s_{t-1} = i)\n",
    "$ conditional  \n",
    "\n",
    "* $\n",
    "\\sum_{i=1}^{N_s} \\alpha_{t-1}(i) p(y_t | s_{t} = j) P(s_t = j | s_{t-1} = i)  \n",
    "= \\sum_{i=1}^{N_s} \\alpha_{t-1}(i) b_j(y_t) a_{ij}\n",
    "$ dropping terms due to Markov order and observation independence\n",
    "\n",
    "To summarize:\n",
    "\n",
    "$\\alpha_t(j) = \\sum_{i=1}^{N_s} \\alpha_{t-1}(i) a_{ij} b_j(y_t) $ for $t = 1, \\dots, N_t$, $j = 1, \\dots, N_s$\n",
    "\n",
    "and set $\\alpha_0 (j) = a_j$ for $j = 1, \\dots, N_s$\n",
    "\n",
    "Notice that $\\alpha_j(N_t) = p_{\\lambda} (y_1, \\dots, y_T, s_{N_t} = j)$, comparing this with the definition of $p_\\lambda(\\mathbf{y})$:\n",
    "\n",
    "$p_\\lambda(\\mathbf{y}) = \\sum_{j = 1}^{N_s} \\alpha_{N_t} (j)$\n",
    "\n",
    "Meaning that the forward algorithm can be used to compute value of the cost function.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.034303700500000006\n"
     ]
    }
   ],
   "source": [
    "function Baum_forward(A,a,B,y)\n",
    "    Nt, Ns = length(y), size(A,1)\n",
    "    alpha = zeros(Nt,Ns)\n",
    "    for j = 1:Ns\n",
    "        alpha[1,j] = a[j]*pdf( B[j], y[1] )\n",
    "    end\n",
    "    \n",
    "    for t = 2:Nt\n",
    "        for j = 1:Ns\n",
    "            for i = 1:Ns\n",
    "                alpha[t,j] += alpha[t-1,i]*A[i,j]*pdf( B[j], y[t] )    \n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return alpha\n",
    "end\n",
    "\n",
    "alpha = Baum_forward(A,a,B,y)\n",
    "@assert sum(Pλ_s .* pλ_y_s) ≈ sum(alpha[end,:]) \n",
    "println(sum(alpha[end,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baum's backwards\n",
    "\n",
    "We can also compute   \n",
    "\n",
    "$\\beta_j (t) = p_{\\lambda} (y_{t+1} \\dots y_{N_t} | s_t = j)$\n",
    "\n",
    "in a similar fashion.\n",
    "\n",
    "By applying similar tricks as before it turns out that by setting\n",
    "\n",
    "$\\beta_j(N_t) = 1 \\ \\forall j = 1, \\dots, N_s$ \n",
    "\n",
    "$\\beta_j(t)$ can be compute going back through time (backwards):\n",
    "\n",
    "$\\beta_j(t) = \\sum_{k=1}^{N_s} \\beta_{t+1}(k) a_{jk} b_k (y_{t+1})$ $t = N_t-1,\\dots,1$.\n",
    "\n",
    "Once we compute this by definition we have:\n",
    "\n",
    "$p_{\\lambda} (\\mathbf{y}) = \\sum_{j = 1}^{N_s} \\alpha_j(t) \\beta_j(t) $ $\\forall t = 1, \\dots N_t$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×1 Array{Float64,2}:\n",
       " 0.0343037005\n",
       " 0.034303700500000006\n",
       " 0.034303700500000006\n",
       " 0.034303700500000006\n",
       " 0.034303700500000006"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Baum_backward(A,B,y)\n",
    "    Nt, Ns = length(y), size(A,1)\n",
    "    beta = zeros(Nt,Ns)\n",
    "    beta[end,:] .= 1\n",
    "    for t = Nt-1:-1:1\n",
    "        for j = 1:Ns\n",
    "            for k = 1:Ns\n",
    "                beta[t,j] += beta[t+1,k]*A[j,k]*pdf( B[k], y[t+1] )\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return beta\n",
    "end\n",
    "\n",
    "beta = Baum_backward(A,B,y)\n",
    "@assert all(sum(alpha.*beta,dims=2) .≈ sum(alpha[end,:]))\n",
    "sum(alpha.*beta,dims=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting posterior probabilities\n",
    "\n",
    "Baum's forward and backward algorithms suffer of underflow: \n",
    "as $N_t$ increases $\\alpha_{N_t} (j) \\rightarrow 0$ $\\beta_1 (j) \\rightarrow 0$.\n",
    "Additionally only likelihoods are calculated.\n",
    "\n",
    "In what follows we show that it is possible to solve the underflow issue and actually obtain _posterior probabilities_ [[3]](#3).\n",
    "\n",
    "Posterior probability is defined as:\n",
    "\n",
    "$$p_{\\lambda}(s_t = j | y_1, \\dots, y_t) = p_\\lambda(s_t = j, y_1, \\dots, y_{N_t}) / p(\\mathbf{y})$$\n",
    "\n",
    "we can split denominator and numerator as before:\n",
    "\n",
    "$\\left( p_\\lambda(s_t = j, y_1, \\dots y_t) \\cdot p_\\lambda(y_1, \\dots y_t | s_t = j) \\right) /\n",
    " \\left( p(y_1, \\dots, y_t) p(y_{t+1} \\dots y_{N_t} | y_1, \\dots, y_t)  \\right)\n",
    "$\n",
    "\n",
    "then we have:\n",
    "* $\n",
    "\\bar{\\alpha}_t(j) = p_\\lambda(s_t = j, y_1, \\dots y_t) /  p(y_1, \\dots, y_t) = p_\\lambda(s_t = j | y_1, \\dots y_t) \n",
    "$\n",
    "  * can be interpreted the probability of being at state $j$ given observations up to $t$.\n",
    "\n",
    "* $\n",
    "\\bar{\\beta}_t(j) = p_\\lambda(y_1, \\dots y_t | s_t = j) /  p(y_{t+1} \\dots y_{N_t} | y_1, \\dots, y_t)\n",
    "$\n",
    "  * has a more difficult interpretation\n",
    "\n",
    "\n",
    "Applying the conditional probability definition on denominator and numerator of $\\bar{\\alpha}_t(j)$:\n",
    "\n",
    "$$\n",
    "\\bar{\\alpha}_t(j) = \n",
    "\\left( p_\\lambda (s_t = j ,y_t | y_1, \\dots, y_{t-1}) p(y_1,\\dots,y_{t-1}) \\right) /\n",
    "\\left( p(y_{t} | y_{1}, \\dots, y_{t-1}) p(y_1,\\dots,y_{t-1}) \\right)\n",
    "$$\n",
    "$$\n",
    "\\bar{\\alpha}_t(j) = \n",
    "p_\\lambda (s_t = j ,y_t | y_1, \\dots, y_{t-1})  /\n",
    "p(y_{t} | y_{1}, \\dots, y_{t-1}) \n",
    "$$\n",
    "\n",
    "Expanding numerator:\n",
    "\n",
    "$\n",
    "p_\\lambda (s_t = j, y_t | y_1, \\dots, y_{t-1}) = \n",
    "\\sum_{i = 1}^{N_s} p_\\lambda (s_{t-1} = i, s_t = j, y_t | y_1, \\dots, y_{t-1})\n",
    "=\n",
    "\\sum_{i = 1}^{N_s} \\bar{\\alpha}_{t-1} (i) a_{ij} b_j (y_t)\n",
    "$\n",
    "\n",
    "Expressing the denominator using the numerator expression: \n",
    "\n",
    "$\n",
    "p(y_{t} | y_{1}, \\dots, y_{t-1}) = \n",
    "\\sum_{j = 1}^{N_s} p_{\\lambda} (s_t = j,y_t | y_1, \\dots, y_{t-1})\n",
    "=\n",
    "\\sum_{j=1}^{N_s} \\sum_{i = 1}^{N_s} \\bar{\\alpha}_{t-1} (i) a_{ij} b_j (y_t)\n",
    "$\n",
    "\n",
    "So we get \n",
    "$\n",
    "\\bar{\\alpha}_t(j) = c_t^{-1}  \\sum_{i=1}^{N_s} \\bar{\\alpha}_{t-1}(i) a_{ij} b_j(y_t)\n",
    "$\n",
    "\n",
    "where $c_t = \\sum_{i = 1}^{N_s} \\bar{\\alpha}_i (t)$. So we have exactly the same as Baum's Forward with the only difference that a scaling $c_t$ is applied.\n",
    "\n",
    "Similar stuff happens for $\\bar{\\beta}_t(j) = c_t^{-1} \\sum_{k=1}^{N_s} \\bar{\\beta}_{t+1}(k) a_{jk} b_k (y_{t+1})$.\n",
    "\n",
    "Posterior probabilities are then given by:\n",
    "\n",
    "$\n",
    "\\gamma_{t}(j) = \\bar{\\alpha}_{t}(j) \\bar{\\beta}_{t}(j) = p(s_t = j | \\mathbf{y}) \n",
    "$\n",
    "\n",
    "They give the probability of being at state $j$ given the future and past observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "<a name=\"1\"></a>[1] Bilmes, Jeff A. \"A gentle tutorial of the EM algorithm and its application to parameter estimation for Gaussian mixture and hidden Markov models.\" International Computer Science Institute 4.510 (1998): 126.\n",
    "\n",
    "<a name=\"2\"></a>[2] Liporace, L. \"Maximum likelihood estimation for multivariate observations of Markov sources.\" IEEE Transactions on Information Theory 28.5 (1982): 729-734.\n",
    "\n",
    "<a name=\"3\"></a>[3] Devijver, Pierre A. \"Baum's forward-backward algorithm revisited.\" Pattern Recognition Letters 3.6 (1985): 369-373."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
